
from datetime import datetime
import pandas as pd
from math import floor
import sys

from geopy.distance import geodesic
from src.GPSReader import GPSReader

# Evlauates data generated by GPSReader
class GPSEvaluator:

    """
    HELPERS
    """
    def __distance_lat_lon(p1,p2) -> float:
        """
        SUMMARY
        returns the euclidean (2D) distance in metres between two lat-lon co-ordinates

        PARAMETERS
        p1 ((float,float)): position one (lat,lon)
        p2 ((float,float)): position two (lat,lon)

        RETURNS
        float: distance in metres between points
        """
        return geodesic(p1,p2).meters

    def time_to_seconds(df:pd.DataFrame) -> pd.Series:
        """
        SUMMARY
        Returns the "time" column as the number of seconds since the first time.
        Assumes that rows are in chronological order.

        PARAMETERS
        df (pandas.DataFrame): dataframe of data produced by GPSReader.read()
                               requires "time" column

        RETURNS
	    pandas.Series: seconds since first time in column
        """
        if "time" in df:
            times=df["time"]
            start_time=times[0]
            return times.apply(lambda x:(x-start_time).seconds).astype(int)
        else: # not enough data
            return None

    """
    EVALUATE DATA
    """

    def distance(df:pd.DataFrame) -> pd.Series:
        """
        SUMMARY
        Produces a series of the euclidean distance between lat-lon co-ordinates.
        Assumes rows are in chronological order

        PARAMETERS
        df (pandas.DataFrame): dataframe of data produced by GPSReader.read().
                               requires "position_lat" & "position_lon" columns

        RETURNS
	    pandas.Series: distance in metres between consecutive co-ordinates
        """

        if ("position_lat" in df.columns) and ("position_lon" in df.columns):
            lat_lon=df[["position_lat","position_lon"]].copy()
            prev_lat_lon=pd.concat([lat_lon.head(1).copy(),lat_lon.iloc[:-1,:].copy()],ignore_index=True) # associate previous lat-lon reading (first is repeated to ensure same length as readings)

            lat_lon["prev_lat"]=prev_lat_lon["position_lat"]
            lat_lon["prev_lon"]=prev_lat_lon["position_lon"]

            lat_lon["distance"]=lat_lon.apply(lambda x:GPSEvaluator.__distance_lat_lon((x["position_lat"],x["position_lon"]),(x["prev_lat"],x["prev_lon"])),axis=1)
            return lat_lon["distance"]

        return None # insufficient data

    def cumm_distance(df:pd.DataFrame) -> pd.Series:
        """
        SUMMARY
        returns series with the cummulative distance along path defined by lat-lon coords

        PARAMETERS
	    df (pandas.DataFrame): dataframe of data produced by GPSReader.read().
                               requires "distance" column with data from GPSEvaluator.distance()
                                        OR "position_lat" & "position_lon" columns

        RETURNS
	    pandas.Series: cummulative distance along path in metres (rounded to 2dp)
        """

        if ("distance" in df.columns): dists=df["distance"]
        elif ("position_lat" in df.columns) and ("position_lon" in df.columns): dists=GPSEvaluator.distance(df)
        else: return None # not enough data

        return dists.cumsum().apply(lambda x:round(x,2))

    def splits(df:pd.DataFrame,split_dist=1000) -> pd.DataFrame:
        """
        SUMMARY
        Calcualtes time taken to complete splits of a defined distance.
        Interpolation is used when measurements don't end exactly on a split.
        Any excess is ignored (ie if distance if 8.9km and readings are made for 1km, .9km will be lost)

        PARAMETERS
	    df (pandas.DataFrame): dataframe of data produced by GPSReader.read().
                               requires "cumm_distance" ("distance" OR ("position_lat" AND "position_lon") are sufficient)
                               AND "seconds" ("time" is sufficient)
        split_dist (int): length of split in metres
                          (default=1000)

        RETURNS
	    pandas.DataFrame: "dist" (cumm distance in metres at end of split), "time" (time in seconds for split)
        """
        # check sufficient data exists
        if "cumm_distance" not in df.columns:
            cumm_dists=GPSEvaluator.cumm_distance(df)
            if cumm_dists is None: return None # not enough data
            df["cumm_distance"]=cumm_dists
        if "seconds" not in df.columns:
            seconds=GPSEvaluator.time_to_seconds(df)
            if seconds is None: return None
            df["seconds"]=seconds

        data=df[["seconds","cumm_distance"]].copy()
        targ_dist=split_dist
        prev_time=0; splits=pd.DataFrame(columns=["dist","time"])

        for _,row in data.iterrows():
            if row["cumm_distance"]>=targ_dist:
                # record values
                split_time=row["seconds"]-prev_time
                new_row=pd.DataFrame({"dist":[targ_dist],"time":split_time})
                splits=splits.append(new_row,ignore_index=True)

                # set up for next split
                targ_dist+=split_dist
                prev_time=row["seconds"]

        return splits

    def split_markers(df:pd.DataFrame,split_dist=1000) -> pd.DataFrame:
        """
        SUMMARY
        Returns the GPS co-ordinates of end point of splits

        PARAMETERS
	    df (pandas.DataFrame): dataframe of data produced by GPSReader.read().
                               requires "position_lat" & "position_lon"
                               ("distance" or "cumm_distance" are ideal but not required)
        split_dist (int): length of split in metres
                          (default=1000)

        RETURNS
	    pandas.DataFrame: "dist", "position_lat","position_lon" of split endpoints
        """
        if "cumm_distance" not in df.columns:
            cumm_dists=GPSEvaluator.cumm_distance(df)
            if cumm_dists is None: return None # not enough data
            df["cumm_distance"]=cumm_dists

        data=df[["position_lat","position_lon","cumm_distance"]]
        split_coords=[]
        target_dist=split_dist
        for _,row in data.iterrows():
            if (row["cumm_distance"]>=target_dist):
                split_coords.append({"dist":target_dist,"position_lat":row["position_lat"],"position_lon":row["position_lon"]})
                target_dist+=split_dist

        return pd.DataFrame(split_coords)

    def important_points(df:pd.DataFrame,name:str) -> pd.Series:
        """
        SUMMARY
        Identifies the lat-lon position of special points.
        Assumes rows are in chronological order

        PARAMETERS
	    df (pandas.DataFrame): dataframe of data produced by GPSReader.read()
                               requires "position_lat" & "position_lon" columns
        name (str): One of ["start","finish"]

        RETURNS
	    pandas.Series: "position_lat" and "position_lon" of position
        """
        if name=="start":  return df.iloc[0][["position_lat"]],df.iloc[0][["position_lon"]]
        if name=="finish": return df.iloc[-1][["position_lat"]],df.iloc[-1][["position_lon"]]
        return None

    """HISTOGRAM"""

    def split_histogram_data(df:pd.DataFrame,bin_width=10,sampling_dist=100,clean=False) -> pd.Series:
        """
        SUMMARY
        Calculate time spent at given splits(speed).
        This data is used to generate a histogram in SVGMaker.generate_histogram

        PARAMETERS
	    df (pandas.DataFrame): dataframe of data produced by GPSReader.read().
                               requires "cumm_distance" ("distance" OR ("position_lat" AND "position_lon") are sufficient)
                               AND "seconds" ("time" is sufficient)
        bin_width (int): width of bin in seconds for seconds per km split
        sampling_dist (int): how often in metres to sample from the data set (default=100)
        clean (bool): remove extreme data

        RETURNS
	    pd.Series: count of samples falling in each bin
                   index is the split in seconds per km
        """

        split_data=GPSEvaluator.splits(df,split_dist=sampling_dist)["time"] # generalise data
        split_data=split_data.apply(lambda x:x*(1000/sampling_dist)).astype(int) # extrapolate km splits

        bins={val:0 for val in range(floor(split_data.min()/bin_width)*bin_width,split_data.max()+1,bin_width)}
        for _,val in split_data.iteritems():
            lower_bound=floor(val/bin_width)*bin_width
            bins[lower_bound]+=1

        bins_ser=pd.Series(bins)
        if clean: return GPSEvaluator.__clean_histogram_data(bins_ser) # remove extreme data
        return bins_ser

    def __clean_histogram_data(splits:pd.Series,min_kept=.9) -> pd.Series:
        """
        SUMMARY
        keeps densiest cluster which contains min_kept% of all values

        PARAMETERS
        splits (pandas.Series): data from GPSEvaluator.split_histogram_data
        min_kept: minimum amount of readings kept

        RETURNS
	    pandas.Series: cleaned data
        """
        clusters=[] # lower & upper values of clusters
        cluster_mass={} # count what % of data cluster holds
        total_mass=splits.sum()

        lower=splits.index[0]; in_cluster=True; mass=0; prev=None # prepare to record clusters
        for bound,count in splits.iteritems():
            mass+=count # mass of current cluster
            if (count==0) and (in_cluster): # end of cluster
                clusters.append((lower,prev))
                cluster_mass[(lower,prev)]=mass/total_mass
                mass=0
                in_cluster=False
            elif (count!=0) and (not in_cluster): # start of cluster
                lower=bound
                in_cluster=True
            prev=bound

        if (in_cluster): # if last cluster runs over end of list
            clusters.append((lower,prev))
            cluster_mass[(lower,prev)]=mass/total_mass

        # keep adding largest cluster until min_kept proportion is met
        min_kept=min(1,min_kept)
        new_splits=pd.Series(); stored_mass=0
        while stored_mass<min_kept: # keep adding largest clusters
            biggest_cluster=max(cluster_mass,key=cluster_mass.get)
            new_splits=new_splits.append(splits.loc[biggest_cluster[0]:biggest_cluster[1]])
            stored_mass+=cluster_mass[biggest_cluster]
            del cluster_mass[biggest_cluster] # so cannot be added again

        # fill in gaps
        width=splits.index[1]-splits.index[0]
        for i in range(new_splits.index.min(),new_splits.index.max(),width):
            if (i not in new_splits.index): new_splits=new_splits.append(pd.Series([0],index=[i]))
        new_splits=new_splits.sort_index()

        return new_splits

    def split_histogram_data_per_km(df:pd.DataFrame,bin_width=10,sampling_dist=100,clean=False) -> pd.DataFrame:
        """
        SUMMARY
        Generate histogram data for each km
        Data used in SVGMaker.generate_animated_histogram()

        PARAMETERS
	    df (pandas.DataFrame): dataframe of data produced by GPSReader.read().
                               requires "cumm_distance" ("distance" OR ("position_lat" AND "position_lon") are sufficient)
                               AND "seconds" ("time" is sufficient)
        bin_width (int): width of bin in seconds for seconds per km split
        sampling_dist (int): how often in metres to sample from the data set (default=100)
        clean (bool): remove extreme data

        RETURNS
	    pandas.DataFrame: column for each km, row for each split.
        """
        if (1000%sampling_dist!=0): return None # non-equal samples per km

        split_data=GPSEvaluator.splits(df,split_dist=sampling_dist)["time"] # generalise data
        split_data=split_data.apply(lambda x:x*(1000/sampling_dist)).astype(int) # extrapolate km splits

        samples_per_km=int(1000/sampling_dist)
        num_kms=floor(len(split_data)/samples_per_km)

        bins={val:0 for val in range(floor(split_data.min()/bin_width)*bin_width,split_data.max()+1,bin_width)}
        rows=[]
        for i in range(num_kms+1):
            local_bins=bins.copy()
            slice=split_data.iloc[i*samples_per_km:(i+1)*samples_per_km]
            for _,split in slice.iteritems(): local_bins[split]+=1
            rows.append(local_bins)

        split_df=pd.DataFrame(rows,index=["km_{}".format(i+1) for i in range(num_kms+1)]).transpose() #columns=["km_{}".format(i+1) for i in range(num_kms+1)]

        if clean: return GPSEvaluator.__clean_def_histogram_data_per_km(split_df)
        return split_df

    def __clean_def_histogram_data_per_km(df:pd.DataFrame,min_kept=.9) -> pd.DataFrame:
        """
        SUMMARY
        keeps densiest cluster which contains min_kept% of all values

        PARAMETERS
    	df (pandas.DataFrame): data from GPSEvaluator.split_histogram_data_per_km

        RETURNS
    	pandas.DataFrame: cleaned data frame
        """
        clusters=[]; cluster_mass={}
        total_mass=df.values.sum()

        lower=df.index[0]; in_cluster=True; mass=0; prev=None # prepare to record clusters
        for bound,row in df.iterrows():
            count=row.sum()
            mass+=count # mass of current cluster
            if (count==0) and (in_cluster): # end of cluster
                clusters.append((lower,prev))
                cluster_mass[(lower,prev)]=mass/total_mass
                mass=0
                in_cluster=False
            elif (count!=0) and (not in_cluster): # start of cluster
                lower=bound
                in_cluster=True
            prev=bound

        if (in_cluster): # if last cluster runs over end of list
            clusters.append((lower,prev))
            cluster_mass[(lower,prev)]=mass/total_mass

        # keep adding largest cluster until min_kept proportion is met
        min_kept=min(1,min_kept)
        new_df=pd.DataFrame(); stored_mass=0
        while stored_mass<min_kept: # keep adding largest clusters
            biggest_cluster=max(cluster_mass,key=cluster_mass.get)
            new_df=pd.concat([new_df,df.loc[biggest_cluster[0]:biggest_cluster[1]]])
            stored_mass+=cluster_mass[biggest_cluster]
            del cluster_mass[biggest_cluster] # so cannot be added again

        # fill in gaps
        width=df.index[1]-df.index[0]
        empty_row=[0 for _ in range(df.shape[1])]
        for i in range(new_df.index.min(),new_df.index.max(),width):
            if (i not in new_df.index): new_df=new_df.append(pd.Series(empty_row,name=i,index=new_df.columns))
        new_df=new_df.sort_index()

        return new_df

if __name__=="__main__":
    reader=GPSReader()
    data,metadata=reader.read("..\examples\Run_from_Exam.tcx")
    df=reader.data_to_dataframe(data)

    split_points=GPSEvaluator.split_markers(df,split_dist=1609)
    print(split_points)
    # df["seconds"]=GPSEvaluator.time_to_seconds(df)
    # df["distance"]=GPSEvaluator.distance(df)
    # df["cumm_distance"]=GPSEvaluator.cumm_distance(df)

    # hist_data=GPSEvaluator.split_histogram_data(df,clean=True)
    # hist_data=GPSEvaluator.split_histogram_data_per_km(df,clean=True)
    # print(hist_data)
